{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando as bibliotecas que serao utilizadas\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets_starbucks_201809061627_ok (1).xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-909ebc32a281>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Lendo os dados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets_starbucks_201809061627_ok (1).xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Legenda'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdados2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets_starbucks_201809061627_ok (1).xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets_starbucks_201809061627_ok (1).xlsx'"
     ]
    }
   ],
   "source": [
    "#Lendo os dados\n",
    "dados = pd.read_excel('tweets_starbucks_201809061627_ok (1).xlsx')\n",
    "dados = dados.drop(columns=['Legenda'])\n",
    "\n",
    "dados2 = pd.ExcelFile('tweets_starbucks_201809061627_ok (1).xlsx')\n",
    "\n",
    "teste = pd.read_excel(dados2, 'Teste')\n",
    "lista= teste[\"Teste\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as listas em função da classificação\n",
    "mi = dados[dados.Classificação == 0]\n",
    "i = dados[dados.Classificação == 1]\n",
    "r = dados[dados.Classificação == 2]\n",
    "mr= dados[dados.Classificação == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a probilidade de um tweet estar dentro de uma determinada classificação\n",
    "pb_mi=len(dados[dados.Classificação == 0])/len(dados[\"Treinamento\"].tolist())\n",
    "pb_i=len(dados[dados.Classificação == 1])/len(dados[\"Treinamento\"].tolist())\n",
    "pb_r=len(dados[dados.Classificação == 2])/len(dados[\"Treinamento\"].tolist())\n",
    "pb_mr=len(dados[dados.Classificação == 3])/len(dados[\"Treinamento\"].tolist())\n",
    "print('Probabilidade de ser muito irrelevante {0:.2f}%'.format(pb_mi*100))\n",
    "print('Probabilidade de ser irrelevante {0:.2f}%'.format(pb_i*100))\n",
    "print('Probabilidade de ser relevante {0:.2f}%'.format(pb_r*100))\n",
    "print('Probabilidade de ser muito relevante {0:.2f}%'.format(pb_mr*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando os dicionarios de cada classificação (muito irrelevante, irrelevante, relevante e muito irrelevante), dentro de cada um desses dicionarios é adicionado cada plavra do grupo e seu respectivo numero de aparições\n",
    "d_mi={}\n",
    "d_i={}\n",
    "d_r={}\n",
    "d_mr={}\n",
    "d_total = {}\n",
    "\n",
    "for tweet in mi['Treinamento']:\n",
    "    palavras=tweet.split()\n",
    "    for p in palavras:\n",
    "        if not p in d_mi:\n",
    "            d_mi[p]=0\n",
    "        d_mi[p]+=1\n",
    "\n",
    "for tweet in i['Treinamento']:\n",
    "    palavras=tweet.split()\n",
    "    for p in palavras:\n",
    "        if not p in d_i:\n",
    "            d_i[p]=0\n",
    "        d_i[p]+=1\n",
    "        \n",
    "for tweet in r['Treinamento']:\n",
    "    palavras=tweet.split()\n",
    "    for p in palavras:\n",
    "        if not p in d_r:\n",
    "            d_r[p]=0\n",
    "        d_r[p]+=1\n",
    "\n",
    "for tweet in mr['Treinamento']:\n",
    "    palavras=tweet.split()\n",
    "    for p in palavras:\n",
    "        if not p in d_mr:\n",
    "            d_mr[p]=0\n",
    "        d_mr[p]+=1\n",
    "        \n",
    "for tweet in dados['Treinamento']:\n",
    "    palavras=tweet.split()\n",
    "    for p in palavras:\n",
    "        if not p in d_total:\n",
    "            d_total[p]=0\n",
    "        d_total[p]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que calcula a quantidade de repetições de cada grupo classificado\n",
    "def soma_valores(d):\n",
    "    soma = 0\n",
    "    for e in d:\n",
    "        soma += d[e]\n",
    "    return soma\n",
    "\n",
    "soma_mi = soma_valores(d_mi)\n",
    "soma_i = soma_valores(d_i)\n",
    "soma_r = soma_valores(d_r)\n",
    "soma_mr = soma_valores(d_mr)\n",
    "\n",
    "num_palavras_diferentes = len(d_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a probabilidade de cada tweet aplicando o Laplace smoothing\n",
    "d_prob_mi={}\n",
    "d_prob_i={}\n",
    "d_prob_r={}\n",
    "d_prob_mr={}\n",
    "\n",
    "for e in d_mi:\n",
    "    d_prob_mi[e]=(d_mi[e]+1)/(soma_mi+num_palavras_diferentes)\n",
    "\n",
    "for e in d_i:\n",
    "    d_prob_i[e]=(d_i[e]+1)/(soma_i+num_palavras_diferentes)\n",
    "\n",
    "for e in d_r:   \n",
    "    d_prob_r[e]=(d_r[e]+1)/(soma_r+num_palavras_diferentes)\n",
    "\n",
    "for e in d_mr:\n",
    "    d_prob_mr[e]=(d_mr[e]+1)/(soma_mr+num_palavras_diferentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nessa etapa foi feita a classificação de cada tweet\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "lista = teste[\"Teste\"].tolist()\n",
    "\n",
    "p_mi=[]\n",
    "p_i=[]\n",
    "p_r=[]\n",
    "p_mr=[]\n",
    "teste_classificacao=[]\n",
    "for jj in lista:\n",
    "    a=jj.split()\n",
    "    for s in a:\n",
    "        if s not in d_prob_mi:\n",
    "            prob = 1/(soma_mi + num_palavras_diferentes)\n",
    "        else:\n",
    "            prob = (d_prob_mi[s]+1)/(soma_mi+num_palavras_diferentes)\n",
    "        p_mi.append(prob)\n",
    "\n",
    "        if s not in d_prob_i:\n",
    "            prob = 1/(soma_i + num_palavras_diferentes)\n",
    "        else:\n",
    "            prob = (d_prob_i[s]+1)/(soma_i+num_palavras_diferentes)\n",
    "        p_i.append(prob)\n",
    "\n",
    "        if s not in d_prob_r:\n",
    "            prob = 1/(soma_r + num_palavras_diferentes)\n",
    "        else:\n",
    "            prob = (d_prob_r[s]+1)/(soma_r+num_palavras_diferentes)\n",
    "        p_r.append(prob)\n",
    "\n",
    "        if s not in d_prob_mr:\n",
    "            prob = 1/(soma_mr + num_palavras_diferentes)\n",
    "        else:\n",
    "            prob = (d_prob_mr[e]+1)/(soma_mr+num_palavras_diferentes)\n",
    "        p_mr.append(prob)\n",
    "\n",
    "        pf_mi=np.prod(p_mi)*pb_mi\n",
    "        pf_i=np.prod(p_i)*pb_i\n",
    "        pf_r=np.prod(p_r)*pb_r\n",
    "        pf_mr=np.prod(p_mr)*pb_mr\n",
    "        \n",
    "        lista_probs=[pf_mi,pf_i,pf_r,pf_mr]\n",
    "        max_valor=lista_probs[0]\n",
    "        indice=0\n",
    "        for i in range(len(lista_probs)):\n",
    "            if lista_probs[i] > max_valor:\n",
    "                max_valor=lista_probs[i]\n",
    "                indice = i \n",
    "        maior_prob=lista_probs[i]\n",
    "    teste_classificacao.append(maior_prob) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a acurácia do programa\n",
    "coluna1 = teste[\"Classificação\"].tolist()\n",
    "tabela = {\"Classificação\": coluna1,'Teste de Classificação':teste_classificacao}\n",
    "tabela = pd.DataFrame(tabela)\n",
    "acertos=0\n",
    "i=0\n",
    "while i < len(coluna1):\n",
    "    if coluna1[i]==teste_classificacao[i]:\n",
    "        acertos+=1\n",
    "    i+=1\n",
    "print(\"Porcentagem de acerto = {0} %\".format(acertos/len(coluna1)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Verificando a performance\n",
    "s=0\n",
    "mi_v=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]==0 and teste_classificacao[s]==0:\n",
    "        mi_v+=1\n",
    "    s+=1\n",
    "porcentagem_mi_v=mi_v*100/len(coluna1)\n",
    "\n",
    "s=0\n",
    "mi_f=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]!=0 and teste_classificacao[s]==0:\n",
    "        mi_f+=1\n",
    "    s+=1\n",
    "porcentagem_mi_f=mi_f*100/len(coluna1)\n",
    "\n",
    "s=0\n",
    "i_v=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]==1 and teste_classificacao[s]==1:\n",
    "        i_v+=1\n",
    "    s+=1\n",
    "porcentagem_i_v=i_v*100/len(coluna1)\n",
    "\n",
    "s=0\n",
    "i_f=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]!=1 and teste_classificacao[s]==1:\n",
    "        i_f+=1\n",
    "    s+=1\n",
    "porcentagem_i_f=i_f*100/len(coluna1)\n",
    "\n",
    "s=0\n",
    "r_v=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]==2 and teste_classificacao[s]==2:\n",
    "        r_v+=1\n",
    "    s+=1\n",
    "porcentagem_r_v=r_v*100/len(coluna1)\n",
    "\n",
    "s=0\n",
    "r_f=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]!=2 and teste_classificacao[s]==2:\n",
    "        r_f+=1\n",
    "    s+=1\n",
    "porcentagem_r_f=r_f*100/len(coluna1)\n",
    "\n",
    "s=0\n",
    "mr_v=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]==3 and teste_classificacao[s]==3:\n",
    "        mr_v+=1\n",
    "    s+=1\n",
    "porcentagem_mr_v=mr_v*100/len(coluna1)\n",
    "\n",
    "s=0\n",
    "mr_f=0\n",
    "while s < len(coluna1):\n",
    "    if coluna1[s]!=3 and teste_classificacao[s]==3:\n",
    "        mr_f+=1\n",
    "    s+=1\n",
    "porcentagem_mr_f=mr_f*100/len(coluna1)\n",
    "print(\"Porcentagem de muito irrelevantes verdadeiros = {0} %\".format(porcentagem_mi_v))\n",
    "print(\"Porcentagem de muito irrelevantes falsos = {0} %\".format(porcentagem_mi_f))\n",
    "print(\"Porcentagem de irrelevantes verdadeiros = {0} %\".format(porcentagem_i_v))\n",
    "print(\"Porcentagem de irrelevantes falsos = {0} %\".format(porcentagem_i_f))\n",
    "print(\"Porcentagem de relevantes verdadeiros = {0} %\".format(porcentagem_r_v))\n",
    "print(\"Porcentagem de relevantes falsos = {0} %\".format(porcentagem_r_f))\n",
    "print(\"Porcentagem de muito relevantes verdadeiros = {0} %\".format(porcentagem_mr_v))\n",
    "print(\"Porcentagem de muito relevantes falsos = {0} %\".format(porcentagem_mr_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
